{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec6d46a-a199-42e8-b273-6c054e307f96",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a2ba3ad3-b4ff-418f-9a74-68576c712b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, TypedDict, Annotated\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import START\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e227d-ba77-431d-ab43-143eb096a877",
   "metadata": {},
   "source": [
    "# Gathering API Keys\n",
    "Langsmith API, OpenAI API, Tavily API keys set as environment variables.\n",
    "\n",
    "LANGSMITH_TRACING=true\n",
    "\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "\n",
    "LANGSMITH_PROJECT=\"homicide-statistics-agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcca5b",
   "metadata": {},
   "source": [
    "# City Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c3f5f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class City(BaseModel):\n",
    "    \"\"\"Homicide statistics for a city\"\"\"\n",
    "    city: Optional[str] = Field(default=None, description=\"The name of the city\")\n",
    "    state: Optional[str] = Field(default=None, description=\"The full name of the state that the city is in, if the state is in the US\")\n",
    "    country: Optional[str] = Field(default=None, description=\"The full name of the country that the city is in\")\n",
    "    homicides: Optional[dict[int, int]] = Field(\n",
    "        default=None, description=\"A dictionary with years as keys, and the homicide count as values\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576c4f9-4910-4d46-b9e4-798f930060e3",
   "metadata": {},
   "source": [
    "# Defining Tools for Agents to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c97081-304d-40cd-876c-f438972bf4ee",
   "metadata": {},
   "source": [
    "### Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fd7e759a-2ac8-4c0d-8fa2-49318fda4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain already has this tool, so no need to define it ourselves\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web given a query\"\"\"\n",
    "    print(f'Searching {query}')\n",
    "    search = TavilySearchResults(max_results=10, include_raw_content=True)\n",
    "    search_results = search.invoke(query)\n",
    "    return str(search_results)\n",
    "\n",
    "# test of this tool\n",
    "# web_query_austin = \"homicide counts in austin texas 2020-2025\"\n",
    "# web_result_austin = search_web(web_query_austin)\n",
    "# web_query_boston = \"homicide counts in boston 2020-2025\"\n",
    "# web_result_boston = search_web(web_query_boston)\n",
    "# print(web_result_austin)\n",
    "# print(web_result_boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21bcb7d-3bca-40e1-ac12-be05cb368042",
   "metadata": {},
   "source": [
    "### Extraction Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "85917265-db8d-47a0-8bdb-ea026b79f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm.\"\n",
    "            \"Only extract relevant information from the text.\"\n",
    "            \"Only extract information for the relevant years.\"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\"\n",
    "            \"It is crucial that you do not return any value, including 0, for years where \"\n",
    "            \"you do not have definitive information. If you are unsure about a value or \"\n",
    "            \"it is not explicitly stated in the text, do not include that year in the output. \"\n",
    "            \"For example, if one of the requested years is 2024 but you do not have confirmed \"\n",
    "            \"data for 2024, do not include 2024 in the homicides dictionary at all.\"\n",
    "            ,\n",
    "        ),\n",
    "        (\"human\", \"{years}\"),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "extraction_llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o-mini\")\n",
    "structured_extraction_llm = extraction_llm.with_structured_output(schema=City)\n",
    "\n",
    "@tool\n",
    "def extract_information(text: str, years: list[int]) -> str:\n",
    "    \"\"\"\n",
    "    Extract relevant homicide counts from the text.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to analyze.\n",
    "\n",
    "    years (list[int]): The relevant years to extract.\n",
    "    \"\"\"\n",
    "    prompt = extraction_prompt_template.invoke({\"text\": text, \"years\": years})\n",
    "    city = structured_extraction_llm.invoke(prompt)\n",
    "    return city.model_dump_json()\n",
    "\n",
    "# test of this tool\n",
    "# extracted_information_austin = extract_information(web_result_austin, [2022, 2023, 2024])\n",
    "# extracted_information_boston = extract_information(web_result_boston, [2022, 2023, 2024])\n",
    "# print(extracted_information_austin)\n",
    "# print(extracted_information_boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9914105d-cad4-4274-bc7e-1b203f449b01",
   "metadata": {},
   "source": [
    "### Extraction Revision Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b8a22c03-b15e-44b2-9b85-4a0416a3163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def revise_extracted_information(old_city: str, new_city: str) -> str:\n",
    "    \"\"\"\n",
    "    Revises old_city by updating it with new information in new_city, if any.\n",
    "    old_city does not have it's values overriden. Only if new_city has additional years in homicides or has values for state or country where old_city has type null will old_city be updated.\n",
    "    old_city and new_city should have the same city name.\n",
    "\n",
    "    Args:\n",
    "    \n",
    "    old_city (str): A JSON-formatted string following the City schema.\n",
    "\n",
    "    new_city (str): A JSON-formatted string following the City schema.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    A JSON-formatted string following the City schema.\n",
    "    \"\"\"\n",
    "    old_data = json.loads(old_city)\n",
    "    old_state = old_data[\"state\"]\n",
    "    old_country = old_data[\"country\"]\n",
    "    new_data = json.loads(new_city)\n",
    "    new_state = new_data[\"state\"]\n",
    "    new_country = new_data[\"country\"]\n",
    "    if old_state is None and new_state is not None: \n",
    "        old_data[\"state\"] = new_state\n",
    "    if old_country is None and new_country is not None: \n",
    "        old_data[\"country\"] = new_country\n",
    "    if \"homicides\" in new_data.keys():\n",
    "        if \"homicides\" in old_data.keys():\n",
    "            for year in new_data[\"homicides\"].keys():\n",
    "                if year not in old_data[\"homicides\"].keys():\n",
    "                    old_data[\"homicides\"][year] = new_data[\"homicides\"][year]\n",
    "        else:\n",
    "            old_data[\"homicides\"] = {}\n",
    "            for year in new_data[\"homicides\"].keys():\n",
    "                old_data[\"homicides\"][year] = new_data[\"homicides\"][year]\n",
    "\n",
    "    return json.dumps(old_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64235251",
   "metadata": {},
   "source": [
    "### Write CSV Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "65525c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_csv(data: str, filename: str, years: list[int]):\n",
    "    \"\"\"\n",
    "    Writes the data to a csv file. This function should only be called the first time the Writer acts.\n",
    "    Data should only be written to a csv until the caller has made multiple attempts to revise and fill in any\n",
    "    NaN/null/None values in the data.\n",
    "\n",
    "    Args:\n",
    "    \n",
    "    data (str): a string that represents a list of JSON-formatted strings that follow the City schema.\n",
    "\n",
    "    filename (str): the name of the file.\n",
    "\n",
    "    years (list[int]): the relevant years.\n",
    "    \"\"\"\n",
    "    city_json = json.loads(data)\n",
    "    with open(filename, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"city\", \"state\", \"country\"] + [str(year) for year in years])\n",
    "        for city in city_json:\n",
    "            row = [city[\"city\"]]\n",
    "            row.append(city[\"state\"]) if city[\"state\"] else row.append(np.nan)\n",
    "            row.append(city[\"country\"]) if city[\"country\"] else row.append(np.nan)\n",
    "            if city[\"homicides\"]:\n",
    "                row.extend(\n",
    "                    [\n",
    "                        str(city[\"homicides\"].get(str(year), np.nan)) for year in years\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                row.extend([np.nan] * len(years))\n",
    "            writer.writerow(row)\n",
    "        \n",
    "    \n",
    "# test of this tool\n",
    "# write_csv(df, \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0c030",
   "metadata": {},
   "source": [
    "### Append CSV Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "23b59f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def append_csv(data: str, years: list[int], filename: str):\n",
    "    \"\"\"\n",
    "    Append data to the csv with filename. This function should be called every time the writer wants to write to a csv, except the first time.\n",
    "    \"\"\"\n",
    "    city = json.loads(data)\n",
    "    row = [city[\"city\"]]\n",
    "    row.append(city[\"state\"]) if city[\"state\"] else row.append(np.nan)\n",
    "    row.append(city[\"country\"]) if city[\"country\"] else row.append(np.nan)\n",
    "    if city[\"homicides\"]:\n",
    "        row.append(\n",
    "            [\n",
    "                city[\"homicides\"][year] if city[\"homicides\"][year] else np.nan for year in years\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        row.append([np.nan] * len(years))\n",
    "    \n",
    "    with open(filename, 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7612f245",
   "metadata": {},
   "source": [
    "### Trying something new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5d44daf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tools = [search_web, extract_information, revise_extracted_information, write_csv, append_csv]\n",
    "agent_prompt = \"\"\"\n",
    "You are an agent tasked with gathering and validating information.\n",
    "Follow these steps strictly:\\n\n",
    "1. First, use search_web to find initial information.\\n\n",
    "2. Use extract_information to process the search results.\\n\n",
    "3. Check the extracted information for any NaN values.\\n\n",
    "4. For each missing value:\\n\n",
    "\\t- Generate a more specific search query focused on finding that particular missing information.\\n\n",
    "\\t- Use search_web with the refined query.\\n\n",
    "\\t- Use revise_extracted_information to update the data with any new findings.\\n\n",
    "5. Repeat step 4 until there are no more NaN values. If you try multiple searches for the same missing value, you should try searches that use synonyms or similar phrase to the original query, while preserving the semantics of the original search.\\n\n",
    "6. Only proceed to write_csv or append_csv when all values are found.\\n\\n\n",
    "\n",
    "Respond with your next action and reasoning.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            agent_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{input}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\").bind_tools(tools)\n",
    "chain = prompt_template | llm\n",
    "\n",
    "def supervisor(state: State):\n",
    "    return {\"messages\": chain.invoke(state[\"messages\"])}\n",
    "graph_builder.add_node(\"supervisor\", supervisor)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"supervisor\") # any time a tool is used, we want to return to the supervisor\n",
    "graph_builder.add_edge(START, \"supervisor\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f99bf87c-310e-4d48-85a8-f21e5d5ce082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_j1fcc4Elk1bDQ9SuEbXmAR0s', 'function': {'arguments': '{\"query\": \"New York City annual homicide counts 2019-2023\"}', 'name': 'search_web'}, 'type': 'function'}, {'id': 'call_0JFFOyhdviXCbgX7t7ha5CM6', 'function': {'arguments': '{\"query\": \"New Orleans annual homicide counts 2019-2023\"}', 'name': 'search_web'}, 'type': 'function'}, {'id': 'call_R3cFICsKa4uOA6lot6KfdLzb', 'function': {'arguments': '{\"query\": \"Los Angeles annual homicide counts 2019-2023\"}', 'name': 'search_web'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 676, 'total_tokens': 766, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-69c29278-8891-4f3d-aab3-e49bee824ffb-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'New York City annual homicide counts 2019-2023'}, 'id': 'call_j1fcc4Elk1bDQ9SuEbXmAR0s', 'type': 'tool_call'}, {'name': 'search_web', 'args': {'query': 'New Orleans annual homicide counts 2019-2023'}, 'id': 'call_0JFFOyhdviXCbgX7t7ha5CM6', 'type': 'tool_call'}, {'name': 'search_web', 'args': {'query': 'Los Angeles annual homicide counts 2019-2023'}, 'id': 'call_R3cFICsKa4uOA6lot6KfdLzb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 676, 'output_tokens': 90, 'total_tokens': 766, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n",
      "------\n",
      "Searching New York City annual homicide counts 2019-2023\n",
      "Searching New Orleans annual homicide counts 2019-2023\n",
      "Searching Los Angeles annual homicide counts 2019-2023\n",
      "{'tools': {'messages': [ToolMessage(content='[{\\'url\\': \\'https://homicidenyc.com/nyc-2023-homicide-victim-list/\\', \\'content\\': \\'17 – John Doe, Male, 40, Shooting, Brooklyn 20 – John Doe, Male, 30, Shooting, Brooklyn 38 – John Doe, Male, 40, Shooting, Brooklyn 39 – John Doe, Male, 20, Shooting Brooklyn 65 – John Doe, Male, Shooting, Brooklyn 72 – John Doe, Male, 37, Shooting, Brooklyn 73 – John Doe, Male ,Shooting, Brooklyn 79 – John Doe, Male, 33, Shooting, Brooklyn 94 – John Doe, Male, 67, Shooting, Brooklyn 115 – John Doe, Male, 26, Shooting, Brooklyn 118 – John Doe, Male, 37, Shooting, Brooklyn May 2023 Total: 32 May 2022 Total: 48 124 – John Doe, Male, 36, Shooting, Brooklyn 163 – John Doe, Male, 29, Shooting, Brooklyn 170 – John Doe, Male, 16, Shooting, Brooklyn\\'}, {\\'url\\': \\'https://abc7ny.com/nypd-crime-shootings-murders/14259597/\\', \\'content\\': \\'NYPD statistics show murders, shootings down in 2023; optimistic about 2024 trends - ABC7 New York ABC7 New York 24/7 Eyewitness News Stream NYPD statistics show murders, shootings down in 2023; optimistic about 2024 NEW YORK CITY (WABC) -- The NYPD released some statistics about safety in New York City during 2023. The number of murders and shootings in the city both decreased last year and are continuing to track downward following the pandemic. New York City had 386 homicides last year, according to new NYPD data, an 11.9% decrease from 2022. * More New York City news NEW YORK CITY\\'}, {\\'url\\': \\'https://www.nyc.gov/site/nypd/news/p00073/nypd-citywide-crime-statistics-january-2023\\', \\'content\\': \"New York\\'s Finest\\\\nNYPD Announces Citywide Crime Statistics for January 2023\\\\nFebruary 3, 2023\\\\nArrests for Overall Index Crimes at a 24-Year High\\\\nFor the month of January 2023, the number of overall shooting incidents and murders in New York City have both declined when compared to January 2022, a result of the NYPD’s enhanced public safety investment across each borough, in every neighborhood. “As we step forward through 2023 and beyond, the women and men of the New York City Police Department are continuing to effectively and efficiently suppress violence, address the drivers of crime, and safeguard our streets and our subways,” said Police Commissioner Keechant L. Sewell. Notably, the number of arrests for index crimes in New York City in January is up 29.6% (4,420 v. 3,410) when compared to the January prior, a month-to-month benchmark unsurpassed since 1999 – nearly a quarter-century.\\\\n This plan has resulted in a 29.3% decrease in major crimes (145 v. 205) in Transit for January 2023, compared to January 2022, led by a 44.3% reduction in grand larceny (54 v. 97) and a 20.7% reduction in robbery (46 v. 58). Reflecting crime-prevention traction taking hold citywide, major crimes in the subway system have dropped precipitously, and arrests for overall index crimes stand at a 24-year high for any January in the modern CompStat era.\"}, {\\'url\\': \\'http://criminaljustice.cityofnewyork.us/wp-content/uploads/2021/01/2020-Shootings-and-Murder-factsheet_January-2021.pdf\\', \\'content\\': \\'Data source: https://en.wikipedia.org/wiki/Crime_in_New_York_City#Murders_by_year 1 Murders in New York City, 1950-2020 There were 462 recorded murders in 2020, up from 319 in 2019 (45 percent increase). 3,000 2,400 1,800 1,200 600 0 1950 1953 1956 1959 1962 1965 1968 1971 1974 1977 1980 1983 1986 1989 1992 1995 1998 2001 2004 2007 2010 2013 2016 2019 2020 Factsheet: 2020 Shootings & Murders Murder Rate, 1985-2020 Large cities across the country experienced the same trends as NYC last year. 2020 2019 Factsheet: 2020 Shootings & Murders Bedford Stuyvesant, Brooklyn* Woodlawn, Bronx Grand Concourse, Bronx* Morrisania, Bronx West Bronx, Bronx * Mott Haven, Bronx East Flatbush, Brooklyn* Northern Crown Heights, Brooklyn* Brownsville, Brooklyn* East New York, Brooklyn* Data source: NYPD 4 *Neighborhoods also having the highest number of shootings in 1993.\\'}, {\\'url\\': \\'https://www.nyc.gov/site/nypd/stats/reports-analysis/homicide.page\\', \\'content\\': \"Reports - Homicide Report - NYPD New York City Police Department311Search all NYC.gov websites New York\\'s Finest Clearance Reports Consent to Search Reports Crime and Enforcement Activity Reports Desk Appearance Ticket Arrest Analysis Data Hate Crimes Reports Homeless Shelter Arrest Data Homicide Reports Marijuana Reports Vehicle Reports Supplementary Homicide Report An NYPD analysis of murders in New York City by calendar year. Supplementary Homicide Report: 2023 (Excel) Supplementary Homicide Report: 2022 (Excel) Supplementary Homicide Report: 2021 (Excel) Supplementary Homicide Report: 2020 (Excel) Supplementary Homicide Report: 2019 (Excel) Supplementary Homicide Report: 2018 (Excel) Supplementary Homicide Report: 2017 (Excel) Supplementary Homicide Report: 2016 (Excel) City of New York. NYC is a trademark and service mark of the City of New York\"}, {\\'url\\': \\'https://www.nyc.gov/site/nypd/news/p00098/nypd-december-2023-end-of-year-citywide-crime-statistics\\', \\'content\\': \"New York\\'s Finest\\\\nNYPD Announces December 2023, End-of-Year Citywide Crime Statistics\\\\nJanuary 4, 2024\\\\nShootings, murder, burglary continue declines as stubborn vehicle thefts drop in December;ongoing reductions seen across most major crime categories in 2023\\\\nMurder, burglary, and the obstinate category of grand larceny-auto each saw sizeable reductions across New York City in December 2023 compared to the same month in 2022, adding to continued overall reductions in five of the seven major index-crime categories for the entire year. For the full year, the number of bias incidents investigated by the NYPD’s Hate Crime Task Force dropped by 32 incidents, or 5% (618 v. 650), but saw a December-to-December increase of 26% additional cases (59 vs. 47) – led by an 8% increase in anti-Jewish incidents.\\\\n Similarly, the category of robbery increased by 22.1% (1572 vs. 1287) in December, but fell by 3.1% (16902 vs. 17442) for the year; while grand larceny rose 1.5% (4323 vs. 4259) in December, but dropped 2.5% (15802 vs. 13741) for the year. Murders – which rose for four consecutive years before the current administration was installed – fell by 11.9% (386 vs. 438) in 2023 compared to 2022, and by 33.3% (24 vs. 36) in December 2023, compared to the same month a year prior. Shooting incidents decreased by double-digit percentages for the month and the year, as well, claiming 416 fewer victims over the course of 2023 – the fourth-lowest number of shooting victims in New York City in more than three decades.\"}, {\\'url\\': \\'https://www.vitalcitynyc.org/dataviz/new-york-city-homicides-and-homicide-rates-1800-2023\\', \\'content\\': \\'1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021\\'}, {\\'url\\': \\'https://crimeresearch.org/2024/05/violent-crime-in-new-york-city-in-2023-up-29-5-over-rate-in-2019/\\', \\'content\\': \\'Concealed Handguns Allowed in Schools, list of States Concealed hanguns Allowed in State Capitols Concealed Handguns Allowed in Schools, How its has worked out Concealed Handguns Used to Stop Mass Public Shootings Concealed Carry - OTHER Constitutional Carry Data from various studies Death Penalty Debates Defensive Gun Uses with Concealed Handguns Demographics of Mass Public Shooters Fact Checking the Media Gun Bans: Murder and Homicide Rates Before and After Gun Bans Gun Control Advocates Refuse to Debate GUN CONTROL LIES Gun-Free Zones Gun Show Regulations IDentifying What States Have different Gun Control Laws Illegal Alien Crime Impact of gun control on the poor International Comparisons Mass Public Killings Non-Shootings Mass Public Shootings Mass PubLIC SHootings in Gun-Free zones Media Appearances Media bias on guns Media Discussion on the CPRC Mental Illness More Guns, Less Crime News Coverage of CPRC Op-eds Police Officer Saved By Concealed Handgun Permit Holder Public Health Research Red Flag Laws Registration of Guns Responses to Critics Safe Storage Laws School Security Smart Guns Stand Your Ground Surveys on gun ownership Talks Television Show Bias on GUns Testimony Women and Guns\\'}, {\\'url\\': \\'https://247wallst.com/special-report/2024/01/12/the-number-of-murders-in-new-york-every-year-since-1995/\\', \\'content\\': \\'Since 1995, New York’s annual murder rate has gone as high as 8.5 homicides per 100,000 people, down to 2.8 per 100,000. While New York’s homicide rate has been lower than that of most other states for over a decade, this has not always been the case. For two years in the mid-1990s, the population adjusted homicide rate in New York ranked among the 20 highest of the 50 states — and in 10 of the last 26 years of available data, New York’s murder rate ranked among the top 50% of states. Using historical data from the FBI’s Uniform Crime Reporting Program, 24/7 Wall St. reviewed New York’s murder rate every year since 1995. A financial advisor can help you understand the advantages and disadvantages of investment properties.\\'}, {\\'url\\': \\'https://www.vitalcitynyc.org/dataviz/new-york-citys-crime-rates-are-higher-than-2019-but-overall-lower-than-2023\\', \\'content\\': \\'Source: CompStat 2.0 (NYPD), NYPD Complaint Data Current (Year to Date) (NYC OpenData), NYPD Complaint Data Historic (NYC OpenData) • Note: The 2024 estimates only represent approximately seven months of data, not a full year. Major crime includes murder, rape, robbery, felony assault, burglary, grand larceny, and grand larceny of an automobile. Violent crime includes murder, rape, robbery\\'}]', name='search_web', id='6e84947f-f28c-4780-8a6c-f4ba6ec5848f', tool_call_id='call_j1fcc4Elk1bDQ9SuEbXmAR0s'), ToolMessage(content='[{\\'url\\': \\'https://www.wdsu.com/article/new-orleans-murders-down-2023/46261395\\', \\'content\\': \\'HOMICIDES ARE DOWN IN THE CITY OF NEW ORLEANS COMPARED TO RECENT YEARS, 193 PEOPLE WERE KILLED IN NEW ORLEANS IN 2023. IT’S GOOD NEWS COUCHED WITHIN BAD NEWS OF OF 193 MURDERS FROM 2020 THROUGH 2022, THE MURDER RATE IN NEW ORLEANS WAS ONE OF THE NATION’S HIGHEST IN 2022, 266 PEOPLE WERE KILLED IN THE CITY. WHILE NOPD RESPONSE TIMES HAVE IMPROVED LAST YEAR, IT’S HARD TO FIND ANY OTHER LOCAL METRIC THAT LED TO THE REDUCTION TRAVERS MACKEL WDSU NEWS. A data analyst in New Orleans says murders were down across the city in 2023 compared to recent years. NEW ORLEANS —A data analyst in New Orleans says murders were down across the city in 2023 compared to recent years.\\'}, {\\'url\\': \\'https://www.nola.com/news/crime_police/how-does-this-years-murder-rate-in-new-orleans-compare-with-previous-years-see-the/article_ed086c84-4599-11ed-a3e1-e75e7b51a8ed.html\\', \\'content\\': \"How does this year\\'s murder rate in New Orleans compare with previous years? How does this year\\'s murder rate in New Orleans compare with previous years? New Orleans is on track to outpace the total number of murders last year, which was the\\\\xa0bloodiest year since Hurricane Katrina. As of noon Thursday, 208 people have been murdered in New Orleans so far in 2022, which is about 30% more than at the same time in 2021, according to data from city officials. The murder count comes from an analysis of information from the New Orleans Police Department and the Orleans Parish Coroner\\'s Office. The\\\\xa0all-time high murder count\\\\xa0was in 1994, when New Orleans police said 424 people were killed.\"}, {\\'url\\': \\'https://crimebulletin.metrocrime.org/wp-content/uploads/2024/06/Orleans-Crime-Trends_as-of-6.16.24.pdf\\', \\'content\\': \\'@metrocrimenola City of New Orleans Calls for Service 2019-2024 Orleans Parish Coroner’s Office NOPD Major Offense Logs Sources: Year Reported Homicide 2024 Change 2024 69 ---2023 120 -43% 2022 142 -51% 2021 92 -25% 2020 72 -4% 2019 55 +25% 55 72 92 142 120 69 2019 2020 2021 2022 2023 2024 Homicide 2023-2024 Change -43% 112 140 237 212 195 118 2019 2020 2021 2022 2023 2024 Shooting 2023-2024 Change -39% Year Reported Shooting 2024 Change 2024 118 ---2023 195 -39% 2022 212 -44% 2021 237 -50% 2020 140 -16% 2019 112 +5% 51 66 140 143 83 44 2019 2020 2021 2022 2023 2024 Carjacking 2023-2024 Change -47% Year Reported Carjacking 2024 Change 2024 44 ---2023 83 -47% 2022 143 -69% 2021 140 -69% 2020 66 -33% 2019 51 -14% 200 155 190 242 216 115 2019 2020 2021 2022 2023 2024 Armed Robbery 2023-2024 Change -47% Year Reported Arm. Rob 2024 Change 2024 115 ---2023 216 -47% 2022 242 -52% 2021 190 -39% 2020 155 -26% 2019 200 -43% For more info, visit Crimebulletin.metrocrime.org @metrocrimenola City of New Orleans Calls for Service 2019-2024 NOPD Major Offense Logs Sources: 3,085 2,316 2,671 2,890 2,442 1,269 2019 2020 2021 2022 2023 2024 Vehicle Burglary 2023-2024 Change -48% Year Reported Veh. Burg.\\'}, {\\'url\\': \\'https://crimebulletin.metrocrime.org/2023-recap/\\', \\'content\\': \\'2023 RECAP: Orleans Crime Trends 2019-2023 – Metrocrime Weekly Crime Bulletin Metrocrime Weekly Crime Bulletin 2023 RECAP: Orleans Crime Trends 2019-2023 2023 Major Violent Crime Map Homicide and Shooting Homicide Victims: 218 5% of 2023 homicides were\\\\xa0Vehicular 3% of 2023 homicides have been classified as\\\\xa0justified 2% of 2023 homicides were negligent Carjacking decreased –47% since 2022, the highest decline of any major violent crime category Armed robbery is the only major violent crime category to show decrease compared with 2019, 2020, 2021, and 2022 PreviousPrevious post:Orleans Crime Trends as of December 17, 2019-2023NextNext post:2023 Homicide Victim Recap All Major Violent Crimes 2024 Orleans Homicide Map 2024 Orleans Shooting Map 2024 Orleans Carjacking Map 2024 Orleans Armed Robbery Map 2024 Search By Category\\'}, {\\'url\\': \\'https://crimebulletin.metrocrime.org/orleans-crime-trends-as-of-october-8-2019-2023/\\', \\'content\\': \\'Orleans Crime Trends as of October 8, 2019-2023 – Metrocrime Weekly Crime Bulletin Orleans Crime Trends as of October 8, 2019-2023 Weekly Violent Crime Map Homicide and Shooting At the same time in 2022, there had been 362 shooting incidents and approximately 494 nonfatal shooting victims (an overall reduction of 19% in fatal/nonfatal shooting incidents and victims). Carjacking incidents are down 47% relative to 2022 – still the biggest decline we are seeing in any major violent crime category since 2022. In 2022, there were 2,839 reported auto thefts as of October 8th. PreviousPrevious post:Orleans Crime Trends as of October 1, 2019-2023NextNext post:Q3 NOPD District-Level Armed Robbery Trends 2019-2023 Orleans Homicide Map 2024 Orleans Shooting Map 2024 Orleans Carjacking Map 2024 Orleans Armed Robbery Map 2024\\'}, {\\'url\\': \\'https://www.nola.com/news/crime_police/new-orleans-murders-in-2023-map-stats-by-neighborhood/article_82b8f908-8bd9-11ed-901e-274373cf0c47.html\\', \\'content\\': \\'New Orleans murders: See map of killings and neighborhood totals for 2023 The following map shows the location of every murder in New Orleans since the start of the year, as well as the total number in each of the official neighborhood boundaries recognized by city officials. A man was killed in a shooting early Tuesday at the edge of the Lower Garden District, New Orleans police said. Woman killed in Mardi Gras shooting on North Claiborne Avenue, New Orleans police say A 50-year-old woman was killed in a shooting on Mardi Gras in New Orleans, police said. Two people were killed and two more were injured in a Saturday night shooting on Beechcraft Street, New Orleans police say.\\'}, {\\'url\\': \\'https://www.nola.com/new-orleans-year-to-date-murder-chart-2023/html_b94e96b6-8bb7-11ed-9345-5b09347ec2d4.html\\', \\'content\\': \\'New Orleans year-to-date murder chart 2023 | | nola.com You are the owner of this html. Edit Html Close You have permission to edit this html. Edit Close New Orleans Jefferson Parish One Tammany Local Politics State Politics Weekly Editions Sports Sports Betting High School Sports Betting Curious Louisiana Louisiana Health Home/Garden Louisiana Inspired Mardi Gras Arthur Hardy - Mardi Gras Guide Our Views Homes Jefferson Parish E-Edition VIEW E-EDITION E-Edition Jefferson Parish One Tammany Local Politics Local Elections State Politics Statewide Elections Weekly Editions East Jefferson St. Tammany Sports Sports Betting High School Sports Betting Curious Louisiana Louisiana Health Home/Garden Louisiana Inspired Mardi Gras Arthur Hardy - Mardi Gras Guide Homes Jefferson Parish New Orleans year-to-date murder chart 2023\\'}, {\\'url\\': \\'https://crimebulletin.metrocrime.org/orleans-crime-trends-as-of-july-16-2019-2023/\\', \\'content\\': \\'Orleans Crime Trends as of July 16, 2019-2023 – Metrocrime Weekly Crime Bulletin Metrocrime Weekly Crime Bulletin CRIME TRENDS WEEKLY CRIME TRENDS CRIME REPORTS CRIME TRENDS ARCHIVE MAJOR VIOLENT CRIME 2024 WEEKLY VIOLENT CRIME CRIME TRENDS WEEKLY CRIME TRENDS CRIME REPORTS CRIME TRENDS ARCHIVE MAJOR VIOLENT CRIME 2024 WEEKLY VIOLENT CRIME Carjacking incidents are down 47% relative to 2022 – still the biggest decline we are seeing in any major violent crime category since 2022. PreviousPrevious post:Q2 Fifth NOPD District Crime Trends as of June 30, 2019-2023NextNext post:Q2 Fourth NOPD District Crime Trends as of June 30, 2019-2023 All Major Violent Crimes 2024 Orleans Homicide Map 2024 Orleans Carjacking Map 2024 Orleans Armed Robbery Map 2024\\'}, {\\'url\\': \\'https://nopdnews.com/post/january-2023-(1)/nopd-releases-2023-annual-crime-statistic-comparis/\\', \\'content\\': \\'Aggravated Assault Announcement armed robbery Assault/Battery Budget Burglary/Theft Business Burglary Canine Unit Carjacking Citizens Academy coffee with cops Community community policing Consent Decree crime cameras Crime Lab Criminal Damage Districts Domestic Domestic Violence DWI Eighth District EPIC False Imprisonment Fifth District First District Fourth District Good Police Work Hit And Run Homicide Horses, Hops & Cops kidnapping Lost Child Missing person/Runaway Modernizing Policing Motorbike Mounted Patrol Narcotics NOLA FOR LIFE NOPJF open data Partnerships Person of Interest Police Training Promotions Reckless Driving Reckless Operation recruitment SafeCam NOLA Safety Tips Second District seventh district sexual assault Sexual Battery Simple Burglary Simple Robbery Sixth District Street Racing Terrorizing Theft Third District TIGER Unit Traffic Accident Traffic Alert Traffic Fatality/Hit and Run Training Transparency Trespass Vehicle of Interest\\'}, {\\'url\\': \\'https://www.nola.com/entertainment_life/arts/artwork-brings-new-orleans-2022-murder-count-to-city-hall/article_9cf226ca-9122-11ed-b785-b71421d1aede.html\\', \\'content\\': \"Artist Mitchell Gaudet produces an annual, symbolic tally of New Orleans murder victims, which he presents publicly, near the steps of City Hall. Artist Mitchell Gaudet, center, talks with a passersby in front of a sculpture he erected at City Hall in New Orleans on Tuesday, January 8, 2019. Artist Mitchell Gaudet produces an annual, symbolic tally of New Orleans murder victims, which he presents publicly, near the steps of City Hall. Artist Mitchell Gaudet, center, talks with a passersby in front of a sculpture he erected at City Hall in New Orleans on Tuesday, January 8, 2019. For eight years, artist Mitchell Gaudet has created a similar sculpture that records the murder tally in New Orleans. ![Image 19: Artist Mitchell Gaudet\\'s sculpture tracks the New Orleans murder rate](blob:https://www.nola.com/17c37ca6bd634b99f272bb6ea5c29dd7)\"}]', name='search_web', id='928f1eec-f9bd-4687-b930-ad7550361873', tool_call_id='call_0JFFOyhdviXCbgX7t7ha5CM6'), ToolMessage(content='[{\\'url\\': \\'https://ktla.com/news/california/l-a-homicide-rate-higher-than-rest-of-state-lower-than-other-major-cities-report/\\', \\'content\\': \\'More than 300 people were murdered within the city of Los Angeles in 2023, creating a homicide rate that is higher than the state as a whole and most other major cities in California. But a new report released by the California Attorney General’s Office, alongside Los Angeles Police Department data, shows that L.A. isn’t close to the city with the nation’s worst homicide rate. While L.A.’s murder rate isn’t enviable (it’s 4 points higher than New York City), LAPD data shows it’s dwarfed by other major metros like Houston (15.1), Chicago (22.5) and Washington D.C., which comes in at an alarming 39.7 murders per 100,000 residents.\\'}, {\\'url\\': \\'https://xtown.la/2023/03/31/murders-decline-in-los-angeles-but-its-not-all-good-news/\\', \\'content\\': \\'Guns were the murder weapon in 75% of the killings last year, according to the Homicide Report. Last year, 341 murder victims were male, and 41 were female, according to the report. Crosstown previously reported that densely packed Downtown experienced 38 homicides last year, according to publicly available LAPD data. Crosstown this month reported that 92 people experiencing homelessness were murdered in 2022, an increase from 85 the prior year. According to LAPD Compstat data, from Jan.1–March 25 of this year, there were 55 murders. How we did it: We examined publicly available crime data from the Los Angeles Police Department from Jan. 1, 2020–March 25, 2023. Subscribe to the Crosstown Newsletter for the latest on air, crime, and traffic in Los Angeles.\\'}, {\\'url\\': \\'https://xtown.la/2024/01/29/a-closer-look-at-the-327-murders-los-angeles-suffered-in-2023/\\', \\'content\\': \\'Homicides in Los Angeles fell 17% in 2023, marking the second consecutive year that the number ticked down. There were 111 murders there last year, down from 146 in 2022, according to the department’s annual Homicide Report. According to publicly available LAPD data, a firearm was the murder weapon 236 times, or in 72% of the killings. An estimated 86% of the murder victims in Los Angeles last year were men. Last year 119 homicide victims, or 36.8% of the total, were Black, according to police data. How we did it: We examined publicly available crime data from the Los Angeles Police Department from Jan. 1, 2010–Dec. 31, 2023. Subscribe to the Crosstown Newsletter for the latest on air, crime, and traffic in Los Angeles.\\'}, {\\'url\\': \\'https://lapdonlinestrgeacc.blob.core.usgovcloudapi.net/lapdonlinemedia/2023-Homicide-Report.pdf\\', \\'content\\': \\'LOS ANGELES POLICE DEPARTMENT 24 11 7 10 4 3 10 13 13 7 2 9 15 9 16 1 9 11 HWD WIL WLA PAC OLYM 2023 2022 2021 HOMICIDES BY AREA HWD WIL WLA PAC OLYM 13 9 4 16 1 7 10 3 9 9 2 13 15 11 10 2023 2022 2021 2023 Clearances 2022 Clearances 2021 Clearances *DQJ\\\\x10UHODWHG\\\\x03UHIHUV\\\\x03WR\\\\x03KRPLFLGHV\\\\x03ZKHUH\\\\x03WKH\\\\x03YLFWLP\\\\x03RU\\\\x03VXVSHFW\\\\x03LV\\\\x03D\\\\x03JDQJ\\\\x03PHPEHU\\\\x03RU\\\\x03DႈOLDWH\\\\x03DQG\\\\x03PD\\\\\\\\\\\\x03LQFOXGH\\\\x03WKH\\\\x03PRWLYH\\\\x03IRU\\\\x03WKH\\\\x03KRPLFLGH\\\\x11\\\\x03)LUHDUP\\\\x03UHIHUV\\\\x03WR\\\\x03KDQGJXQV\\\\x0f\\\\x03ULÀHV\\\\x0f\\\\x03DQG\\\\x03VKRWJXQV\\\\x11\\\\x03\\\\x03 DOMESTIC VIOLENCE 2023 2022 2021 HOMELESS-RELATED 2023 2022 2021 GANG-RELATED 2023 2022 2021 HOLLYWOOD 1 1 0 HOLLYWOOD 0 4 3 HOLLYWOOD 6 4 2 WILSHIRE 0 1 1 WILSHIRE 1 3 4 WILSHIRE 1 2 8 WEST LOS ANGELES 0 0 0 WEST LOS ANGELES 0 2 0 WEST LOS ANGELES 3 0 0 PACIFIC 0 1 0 PACIFIC 5 3 5 PACIFIC 2 1 3 OLYMPIC 0 3 3 OLYMPIC 5 5 6 OLYMPIC 6 6 3 TOTAL 1 6 4 11 17 18 18 13 16 2023 95% CLEARANCE RATE O P E R A T I O N S - W E S T B U R E A U 1 , 1 9 9 = 200 FIREARMS SEIZED OWB accounted for 15 percent of the 8,154 ¿UHDUPV\\\\x03VHL]HG\\\\x03 in 2022, three percent fewer than in 2022.\\'}, {\\'url\\': \\'https://publichealth.lacounty.gov/chie/reports/Homeless_Mortality_Report_2024.pdf\\', \\'content\\': \\'Cause of Death MRR All Causes of Death 3.9 Drug and Alcohol Overdose 40.5 Coronary Heart Disease 4.3 Transportation-Related Injury 18.3 Homicide 17.7 Suicide 8.4 COVID-19 1.7 *The MRR is the mortality rate among PEH divided by the mortality rate in the total LA County population Table 2: Age- and Gender-Adjusted Mortality Rate Ratios (MRRs)*: PEH Compared to LA County Population (2021 and 2022 Combined) MORTALITY RATES AND CAUSES OF DEATH AMONG PEH IN LA COUNTY: 2014-2022 22 mortality among 40-to-49-year-olds also increased in 2022.\\'}, {\\'url\\': \\'https://lasd.org/transparency/homicidereports/\\', \\'content\\': \"Homicide Reports | Los Angeles County Sheriff\\'s Department LASD Stations Inmate Book Donations Public Complaint and Commendation Transparency Main The reports and statistics on this page are reflective of murder incidents investigated by the Los Angeles County Sheriff’s Department – Homicide Bureau. The homicide data is gathered from areas patrolled by the Los Angeles County Sheriff’s Department. This data file contains Murder incidents investigated by the Los Angeles County Sheriff’s Department – Homicide Bureau which occurred in Los Angeles County Sheriff’s Department patrol areas from 1925 to present. Los Angeles County Sheriff’s Department Homicides from 1925 – 2023 – PDF 2023 Homicide Report – PDF Back to Transparency Main LASD Stations Inmate Book Donations Public Complaint and Commendation\"}, {\\'url\\': \\'https://data.lacounty.gov/maps/lacounty::homicide-rate/about\\', \\'content\\': \\'Homicide Rate (Deaths per 100,000 Population), single year (2022) and multi-year aggregate (2018-2022). Data provided by Los Angeles County Department of Public Health (DPH) for the Community Health Profiles (CHP) Data Initiative.\\'}, {\\'url\\': \\'https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8\\', \\'content\\': \\'Data CatalogGeohubBlogDeveloper ResourcesAboutSign In\\'}, {\\'url\\': \\'https://data.lacounty.gov/datasets/homicide-rate/explore\\', \\'content\\': \"Homicide Rate | County of Los Angeles Open Data Data Data provided by Los Angeles County Department of Public Health (DPH) for the Community Health Profiles (CHP) Data Initiative. View Full Details Download Data Updated View data table View license details Start a map with this data  View API Resources View Data Source Select to open in a new tab View All Metadata Select to open in a new tab Explore Feeds Add RSS (guide) to an aggregator such as Inoreader or Feedly and see daily changes to this site\\'s content. Use the DCAT feeds to federate this site\\'s content with external catalogs like data.gov or data.europa.eu. Use the OGC Records API to discover geospatial resources through standardized collections and resources metadata.\"}, {\\'url\\': \\'http://www.publichealth.lacounty.gov/chie/reports/Homeless_Mortality_Report_2023.pdf\\', \\'content\\': \\'More PEH died of overdoses in 2020 and 2021 than in at least the six previous years Cause of Death 2017-2019 2020-2021 (new age groups) All Causes 2.9 3.8 Drug Overdose 36.4 38.9 Coronary Heart Disease 3.8 4.4 Transportation-Related Injury 16.4 20.4 Homicide 14.9 15.1 Suicide 7.5 8.4 COVID-19 NA 1.8 Years Table 2: Age- and Gender-Adjusted Mortality Rate Ratios (MRRs): PEH Compared to LA County Population* * The MRR is the mortality rate among PEH divided by the mortality rate in the General LA County population.\\'}]', name='search_web', id='ddf2e1be-b72a-4334-8ceb-297556b7ac11', tool_call_id='call_R3cFICsKa4uOA6lot6KfdLzb')]}}\n",
      "------\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[223], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDetermine the annual homicide counts from 2019-2023 (inclusive) for New York, New Orleans, and Los Angeles, and write them to \u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43mtest.csv\u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43m. If you don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt find all the requested values on the first web search, make a refined web search to search for what is missing, and revise the data.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1670\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1677\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\runner.py:171\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    169\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:448\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    445\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    446\u001b[0m )\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:219\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 219\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[222], line 41\u001b[0m, in \u001b[0;36msupervisor\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msupervisor\u001b[39m(state: State):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m}\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3021\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:781\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 781\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1282\u001b[0m     )\n\u001b[1;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1049\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1048\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1098\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1049\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1048\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1098\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1073\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "\u001b[0mDuring task with name 'supervisor' and id '3332eede-2e55-6cbc-cf1b-be4c1a46a86e'"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Determine the annual homicide counts from 2019-2023 (inclusive) for New York, New Orleans, and Los Angeles, and write them to \\\"test.csv\\\". If you don't find all the requested values on the first web search, make a refined web search to search for what is missing, and revise the data.\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd2f64",
   "metadata": {},
   "source": [
    "This approach successfully writes data to a csv, but some of the homicide numbers are inaccurate. We can revise the agent's system prompt by instructing it to search for each value one at a time, preventing it from attempting \"batch searches\". We may still get some \"batches\" if the extraction tool is able to find multiple values. While this is slower, it increases the accuracy of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fdaa65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class State(TypedDict):\n",
    "#     messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# graph_builder = StateGraph(State)\n",
    "\n",
    "# tools = [search_web, extract_information, revise_extracted_information, write_csv, append_csv]\n",
    "# agent_prompt = \"\"\"\n",
    "# You are an agent tasked with gathering and validating information. You are given a set of values to search for.\n",
    "# For example, you may be asked to find homicide counts for a number of cities across a range of years, then you must find the homicide counts for all cities across all requested years.\n",
    "# A particular requested value is a homicide count for a particular year in a particular city.\n",
    "# For each particular requested value, strictly follow these steps:\\n\n",
    "# \\t1. Use search_web to find information about a particular value. Your search query should \n",
    "# be specific to one city and one year at a time. For example, \\\"New York City homicide count 2019\\\"\n",
    "# or \\\"Los Angeles homicide count 2020\\\".\\n\n",
    "# \\t2. Use extract_information to process the search results.\\n\n",
    "# \\t3. If the value sought for is still NaN:\n",
    "# \\t\\t- Generate a more specific search query focused on finding that particular missing value, still keeping it to one city and one year.\\n\n",
    "# \\t\\t- Use search_web with the refined query.\\n\n",
    "# \\t\\t- Use revise_extracted_information to update the data with any new findings.\\n\n",
    "# Repeat steps 1-3 for the next requested value until all values are found. Use revise_extracted_information to update the data with any findings.\n",
    "# Only proceed to write_csv or append_csv when all values are found.\\n\\n\n",
    "\n",
    "# Respond with your next action and reasoning.\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             agent_prompt,\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"{input}\"\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\").bind_tools(tools)\n",
    "# chain = prompt_template | llm\n",
    "\n",
    "# def supervisor(state: State):\n",
    "#     return {\"messages\": chain.invoke(state[\"messages\"])}\n",
    "# graph_builder.add_node(\"supervisor\", supervisor)\n",
    "\n",
    "# tool_node = ToolNode(tools=tools)\n",
    "# graph_builder.add_node(\"tools\", tool_node)\n",
    "# graph_builder.add_conditional_edges(\n",
    "#     \"supervisor\",\n",
    "#     tools_condition,\n",
    "# )\n",
    "# graph_builder.add_edge(\"tools\", \"supervisor\") # any time a tool is used, we want to return to the supervisor\n",
    "# graph_builder.add_edge(START, \"supervisor\")\n",
    "# graph = graph_builder.compile()\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ac3ed73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             HumanMessage(content=\"Determine the annual homicide counts from 2019-2023 (inclusive) for New York, New Orleans, and Los Angeles, and write them to \\\"test.csv\\\".\")\n",
    "#         ]\n",
    "#     }\n",
    "# ):\n",
    "#     if \"__end__\" not in s:\n",
    "#         print(s)\n",
    "#         print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72727dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
